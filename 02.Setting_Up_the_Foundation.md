# Setting Up the Foundation

## The Infrastructure


```bash
# install zip and unzip
apt update
apt install zip unzip jq -y
```


```bash
# Set the Terraform version
TERRAFORM_VERSION="1.10.3"
TERRAFORM_ZIP="terraform_${TERRAFORM_VERSION}_linux_amd64.zip"
TERRAFORM_URL="https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/${TERRAFORM_ZIP}"

# Download and extract the Terraform binary
curl -LO $TERRAFORM_URL
unzip $TERRAFORM_ZIP
mv terraform /usr/local/bin/
```


```bash
# First of all, choose a directory where you want to store the files we will use.
PROJECT_NAME="learning-rancher"

# Create the folder structure
mkdir -p $PROJECT_NAME
```


```bash
# Create a unique name for the SSH key to avoid conflicts
# with other keys in your ~/.ssh directory
# Make sure you are not overwriting an existing key
SSH_UNIQUE_NAME="$HOME/.ssh/$PROJECT_NAME"

# generate the keys (public and private)
# This will overwrite the keys if they already exist
ssh-keygen -t rsa \
    -b 4096 \
    -C "$PROJECT_NAME" \
    -f $SSH_UNIQUE_NAME -N "" \
    <<< y

# add the key to the ssh-agent
ssh-add $SSH_UNIQUE_NAME
```


```bash
# Export the DigitalOcean token. 
# Get one here: https://cloud.digitalocean.com/account/api/tokens
export DIGITALOCEAN_TOKEN="[CHANGE_ME]"

# Choose the best region for you. 
# More options here: https://www.digitalocean.com/docs/platform/availability-matrix/
export DIGITALOCEAN_REGION="fra1"

# I recommend using Ubuntu 24.04 for this project.
export DIGITALOCEAN_IMAGE="ubuntu-24-04-x64"

# SSH key variables
export DIGITALOCEAN_SSH_KEY_NAME="$SSH_UNIQUE_NAME"
export DIGITALOCEAN_SSH_PUBLIC_KEY_PATH="$SSH_UNIQUE_NAME.pub"
export DIGITALOCEAN_SSH_PRIVATE_KEY_PATH="$SSH_UNIQUE_NAME"

# VPC variables. 
# You can use the default VPC or create a new one.
# Use doctl to get the VPC UUID (`doctl vpcs list`)
export DIGITALOCEAN_VPC_UUID="[CHANGE_ME]"
export DIGITALOCEAN_PROJECT_NAME="$PROJECT_NAME"

# Workspace cluster variables
export DIGITALOCEAN_WORKSPACE_VM_NAME="workspace"
export DIGITALOCEAN_WORKSPACE_VM_SIZE="s-4vcpu-8gb"

# Workload cluster variables
export DIGITALOCEAN_WORKLOAD_VMS_NAMES='["rke2-controlplane-01", "rke2-node-01", "rke2-extlb-01"]'
export DIGITALOCEAN_WORKLOAD_VMS_SIZE="s-4vcpu-8gb"
```


```bash
# Create a Terraform variable file. 
cat << EOF > $PROJECT_NAME/variables.tf
variable "region" {
  default = "${DIGITALOCEAN_REGION}"
}
variable "image" {
  default = "${DIGITALOCEAN_IMAGE}"
}
variable "vpc_uuid" {
  default = "${DIGITALOCEAN_VPC_UUID}"
}
variable "workspace_vm_size" {
  default = "${DIGITALOCEAN_WORKSPACE_VM_SIZE}"
}
variable "workspace_vm_name" {
  default = "${DIGITALOCEAN_WORKSPACE_VM_NAME}"
}
variable "workload_vms_size" {
  default = "${DIGITALOCEAN_WORKLOAD_VMS_SIZE}"
}
variable "workload_vms_names" {
  default = ${DIGITALOCEAN_WORKLOAD_VMS_NAMES}
}
variable "project_name" {
  default = "${DIGITALOCEAN_PROJECT_NAME}"
}
variable "ssh_key_name" {
  default = "${DIGITALOCEAN_SSH_KEY_NAME}"
}
variable "ssh_public_key_path" {
  default = "${DIGITALOCEAN_SSH_PUBLIC_KEY_PATH}"
}
variable "ssh_private_key_path" {
  default = "${DIGITALOCEAN_SSH_PRIVATE_KEY_PATH}"
}
EOF
```


```bash
cat << EOF > $PROJECT_NAME/main.tf
terraform {
  required_providers {
    digitalocean = {
      source = "digitalocean/digitalocean"
      version = "~> 2.0"
    }
  }
}

# Create a DigitalOcean project
resource "digitalocean_project" "learning_rancher_project" {
  name        = var.project_name
  description = "Project for managing Rancher VMs"
  purpose     = "Development"
  environment = "Development"
}

data "digitalocean_project" "project" {
  depends_on = [digitalocean_project.learning_rancher_project]
  name       = var.project_name
}

# Resource: Define the SSH key to be used for all VMs
resource "digitalocean_ssh_key" "default_ssh_key" {
  name       = var.ssh_key_name
  public_key = file(var.ssh_public_key_path)
}

# Resource: Workload VMs
resource "digitalocean_droplet" "workload_vms" {
  for_each = { for name in var.workload_vms_names : name => name }

  image      = var.image
  name       = each.value
  region     = var.region
  size       = var.workload_vms_size
  ssh_keys   = [digitalocean_ssh_key.default_ssh_key.id]
  monitoring = false
  vpc_uuid   = var.vpc_uuid

  connection {
    agent       = false
    type        = "ssh"
    user        = "root"
    private_key = file(var.ssh_private_key_path)
    host        = self.ipv4_address
    timeout     = "5m"
  }
}

# Resource: Workspace VM
resource "digitalocean_droplet" "workspace_vm" {
  image      = var.image
  name       = var.workspace_vm_name
  region     = var.region
  size       = var.workspace_vm_size
  ssh_keys   = [digitalocean_ssh_key.default_ssh_key.id]
  monitoring = false
  vpc_uuid   = var.vpc_uuid

  connection {
    agent       = false
    type        = "ssh"
    user        = "root"
    private_key = file(var.ssh_private_key_path)
    host        = self.ipv4_address
    timeout     = "5m"
  }
}

# Resource: Add all VMs to the project
resource "digitalocean_project_resources" "project_resources" {
  project = data.digitalocean_project.project.id
  resources = concat(
    [for vm in digitalocean_droplet.workload_vms : vm.urn],
    [digitalocean_droplet.workspace_vm.urn]
  )
}

# Output: Combined public and private IPs of all VMs (workload and workspace)
output "all_vm_ips" {
  value = merge(
    { for vm in digitalocean_droplet.workload_vms :
      vm.name => {
        public_ip  = vm.ipv4_address
        private_ip = vm.ipv4_address_private
      }
    },
    {
      (var.workspace_vm_name) = {
        public_ip  = digitalocean_droplet.workspace_vm.ipv4_address
        private_ip = digitalocean_droplet.workspace_vm.ipv4_address_private
      }
    }
  )
}
EOF
```


```bash
terraform -chdir=$PROJECT_NAME init
terraform -chdir=$PROJECT_NAME apply -auto-approve
```


```bash
terraform -chdir=$PROJECT_NAME output
```


```bash
# Save the output of the droplet IPs as JSON
terraform -chdir=$PROJECT_NAME output -json all_vm_ips \
  > $PROJECT_NAME/all_vm_ips.json
```


```bash
# Extract IPs using jq and export them as environment variables
JSON_FILE="$PROJECT_NAME/all_vm_ips.json"

# The public and private IPs of the workspace server
export WORKSPACE_PUBLIC_IP=$(jq -r '.workspace.public_ip' $JSON_FILE)
export WORKSPACE_PRIVATE_IP=$(jq -r '.workspace.private_ip' $JSON_FILE)

# The public and private IPs of the workload server (control plane)
export WORKLOAD_CONTROLPLANE_01_PUBLIC_IP=$(jq -r '."rke2-controlplane-01".public_ip' $JSON_FILE)
export WORKLOAD_CONTROLPLANE_01_PRIVATE_IP=$(jq -r '."rke2-controlplane-01".private_ip' $JSON_FILE)

# The public and private IPs of the workload server (node)
export WORKLOAD_NODE_01_PUBLIC_IP=$(jq -r '."rke2-node-01".public_ip' $JSON_FILE)
export WORKLOAD_NODE_01_PRIVATE_IP=$(jq -r '."rke2-node-01".private_ip' $JSON_FILE)

# The public and private IPs of the external load balancer
export WORKLOAD_EXTLB_01_PUBLIC_IP=$(jq -r '."rke2-extlb-01".public_ip' $JSON_FILE)
export WORKLOAD_EXTLB_01_PRIVATE_IP=$(jq -r '."rke2-extlb-01".private_ip' $JSON_FILE)
```


```bash
cat << EOF > $PROJECT_NAME/variables.sh && source $PROJECT_NAME/variables.sh
export WORKSPACE_PUBLIC_IP="$WORKSPACE_PUBLIC_IP"
export WORKSPACE_PRIVATE_IP="$WORKSPACE_PRIVATE_IP"
export WORKLOAD_CONTROLPLANE_01_PUBLIC_IP="$WORKLOAD_CONTROLPLANE_01_PUBLIC_IP"
export WORKLOAD_CONTROLPLANE_01_PRIVATE_IP="$WORKLOAD_CONTROLPLANE_01_PRIVATE_IP"
export WORKLOAD_NODE_01_PUBLIC_IP="$WORKLOAD_NODE_01_PUBLIC_IP"
export WORKLOAD_NODE_01_PRIVATE_IP="$WORKLOAD_NODE_01_PRIVATE_IP"
export WORKLOAD_EXTLB_01_PUBLIC_IP="$WORKLOAD_EXTLB_01_PUBLIC_IP"
export WORKLOAD_EXTLB_01_PRIVATE_IP="$WORKLOAD_EXTLB_01_PRIVATE_IP"
EOF
```

```bash
# Copy SSH keys and variables file, create project directory, and update bashrc
for SERVER in "${SERVERS[@]}"; do
  echo "Processing server: $SERVER"
  
  # Ensure .ssh directory exists on the remote server
  ssh -o StrictHostKeyChecking=accept-new root@"$SERVER" "mkdir -p ~/.ssh"
  
  # Copy SSH keys
  scp "$SSH_UNIQUE_NAME"* root@"$SERVER":~/.ssh/
  
  # Ensure project directory exists on the remote server
  ssh -o StrictHostKeyChecking=accept-new root@"$SERVER" "mkdir -p ~/learning-rancher"
  
  # Copy variables file to the remote project directory
  scp "$PROJECT_NAME/variables.sh" root@"$SERVER":~/learning-rancher/
  
  # Update bashrc
  ssh root@"$SERVER" "cat << 'EOF' >> ~/.bashrc
source ~/learning-rancher/variables.sh
eval \$(ssh-agent -s)
ssh-add ~/.ssh/$PROJECT_NAME
EOF
"
done
```


```bash
# Source the variables file
source $PROJECT_NAME/variables.sh

# Copy the Terraform project to the workspace server
scp -r $PROJECT_NAME root@$WORKSPACE_PUBLIC_IP:~/

# If you want to use Terrafrom from the workspace server, you should:
# - Install Terraform
# - Change the path to SSH keys in variables.tf to the correct path
```


## The Application


```bash
# Update the package list
apt update
# Install Python 3.12
apt install python3.12 -y
# Install Virtualenv
apt install python3-pip -y
pip install virtualenv --break-system-packages
```


```bash
mkdir -p $HOME/todo/app
```


```bash
cd $HOME/todo/app
# Create a new virtual environment
virtualenv venv
# Activate the virtual environment
source venv/bin/activate
```


```bash
curl -fsSL https://raw.githubusercontent.com/github/gitignore/main/Python.gitignore \
-o $HOME/todo/app/.gitignore
```


```bash
pip install Flask==3.0.0
pip freeze > $HOME/todo/app/requirements.txt
```


```python
cat << EOF> $HOME/todo/app/app.py
# Import the required libraries from Flask and SQLite.
from flask import Flask, jsonify, request
import sqlite3
import os

# Create a Flask application instance.
app = Flask(__name__)

# Define the database file path.
DATABASE_NAME = os.environ.get('DATABASE_NAME', 'todo.db')
DATABASE_FOLDER = os.environ.get('DATABASE_PATH', "/var/data/todo-app")
DATABASE_PATH = f'{DATABASE_FOLDER}/{DATABASE_NAME}'

# Ensure the directory exists.
os.makedirs(os.path.dirname(DATABASE_PATH), exist_ok=True)

# Database initialization function
def init_db():
    # Connect to the SQLite database (it will be created if it doesn't exist).
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()

    # Create the 'tasks' table if it doesn't already exist.
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS tasks (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT NOT NULL,
            description TEXT NOT NULL
        )
    ''')

    # Commit changes and close the connection.
    conn.commit()
    conn.close()

# Define a route to handle GET requests to retrieve all tasks.
@app.route('/tasks', methods=['GET'])
def get_tasks():
    # Connect to the database and fetch all tasks.
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    cursor.execute('SELECT * FROM tasks')
    rows = cursor.fetchall()
    conn.close()

    # Convert rows into a list of dictionaries.
    tasks = [{'id': row[0], 'title': row[1], 'description': row[2]} for row in rows]

    # Return a JSON response containing the list of all tasks.
    return jsonify({'tasks': tasks})

# Define a route to handle POST requests to add a new task.
@app.route('/tasks', methods=['POST'])
def add_task():
    # Get the task details from the request body.
    title = request.json['title']
    description = request.json['description']

    # Connect to the database and insert the new task.
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    cursor.execute(
      'INSERT INTO tasks (title, description) VALUES (?, ?)', (title, description)
    )
    conn.commit()

    # Get the ID of the newly inserted task.
    task_id = cursor.lastrowid
    conn.close()

    # Create the task dictionary.
    task = {'id': task_id, 'title': title, 'description': description}

    # Return the newly created task as a JSON response with a 201 HTTP status code.
    return jsonify(task), 201

# Launch the Flask application.
if __name__ == '__main__':
    # Initialize the database.
    init_db()

    app.run(debug=True, host='0.0.0.0', port=5000)
EOF
```


## The Container Image


```Dockerfile
cat << EOF > $HOME/todo/app/Dockerfile
# Use an official Python runtime as a parent image
FROM python:3.12-slim
# Set the working directory to /app
WORKDIR /app
# Copy the current directory contents into the container at /app
COPY . /app
# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt
# Make port 5000 available to the world outside this container
EXPOSE 5000
# Define environment variable
CMD ["python", "app.py"]
EOF
```


```bash
cat << EOF > $HOME/todo/app/.dockerignore
.git
.gitignore
__pycache__
venv
tests
Dockerfile
EOF
```

    
```bash
# Download the Docker installation script
curl -s https://get.docker.com | sh
```


```bash
docker build -t todo-app $HOME/todo/app
```


```bash
docker run -d -p 5000:5000 todo-app
```


```bash
curl -X POST \
http://localhost:5000/tasks \
-H "Content-Type: application/json" \
-d '{
        "title": "Buy groceries", 
        "description": "Eggs, bread, cheese and coffee"
}'
```


```json
{
  "id": 1,
  "title": "Buy groceries",
  "description": "Eggs, bread, cheese and coffee"  
}
```


```bash
docker stop $(docker ps -q)
```